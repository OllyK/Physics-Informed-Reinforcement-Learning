Failure # 1 (occurred at 2022-10-04_19-10-09)
Traceback (most recent call last):
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/tune/execution/ray_trial_executor.py", line 989, in get_next_executor_event
    future_result = ray.get(ready_future)
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/_private/client_mode_hook.py", line 105, in wrapper
    return func(*args, **kwargs)
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/_private/worker.py", line 2277, in get
    raise value
ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, [36mray::ApexDQN.__init__()[39m (pid=160242, ip=143.248.153.115, repr=ApexDQN)
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py", line 125, in __init__
    self.add_workers(
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py", line 269, in add_workers
    self.foreach_worker(lambda w: w.assert_healthy())
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py", line 391, in foreach_worker
    remote_results = ray.get([w.apply.remote(func) for w in self.remote_workers()])
ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, [36mray::RolloutWorker.__init__()[39m (pid=160274, ip=143.248.153.115, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fa6419f10a0>)
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py", line 189, in check_gym_environments
    raise ValueError(error)
ValueError: The observation collected from env.reset() was not  contained within your env's observation space. Its possible that There was a type mismatch, or that one of the sub-observations  was out of bounds: 

 reset_obs: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]

 env.observation_space: Box(-1.0, 1.0, (1, 256), float64)

 reset_obs's dtype: float64

 env.observation_space's dtype: float64

During handling of the above exception, another exception occurred:

[36mray::RolloutWorker.__init__()[39m (pid=160274, ip=143.248.153.115, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fa6419f10a0>)
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py", line 495, in __init__
    check_env(self.env)
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py", line 83, in check_env
    raise ValueError(
ValueError: Traceback (most recent call last):
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py", line 72, in check_env
    check_gym_environments(env)
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py", line 189, in check_gym_environments
    raise ValueError(error)
ValueError: The observation collected from env.reset() was not  contained within your env's observation space. Its possible that There was a type mismatch, or that one of the sub-observations  was out of bounds: 

 reset_obs: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]

 env.observation_space: Box(-1.0, 1.0, (1, 256), float64)

 reset_obs's dtype: float64

 env.observation_space's dtype: float64

The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).

During handling of the above exception, another exception occurred:

[36mray::ApexDQN.__init__()[39m (pid=160242, ip=143.248.153.115, repr=ApexDQN)
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py", line 308, in __init__
    super().__init__(config=config, logger_creator=logger_creator, **kwargs)
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/tune/trainable/trainable.py", line 157, in __init__
    self.setup(copy.deepcopy(self.config))
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/rllib/algorithms/apex_dqn/apex_dqn.py", line 349, in setup
    super().setup(config)
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py", line 443, in setup
    raise e.args[0].args[2]
ValueError: Traceback (most recent call last):
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py", line 72, in check_env
    check_gym_environments(env)
  File "/home/anthony/.pyenv/versions/py39/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py", line 189, in check_gym_environments
    raise ValueError(error)
ValueError: The observation collected from env.reset() was not  contained within your env's observation space. Its possible that There was a type mismatch, or that one of the sub-observations  was out of bounds: 

 reset_obs: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]

 env.observation_space: Box(-1.0, 1.0, (1, 256), float64)

 reset_obs's dtype: float64

 env.observation_space's dtype: float64

The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).

