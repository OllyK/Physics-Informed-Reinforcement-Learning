{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anthony/.pyenv/versions/3.9.14/envs/py39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray import air\n",
    "from deflector_gym.wrappers import ExpandObservation, BestRecorder\n",
    "from ray.tune import register_env\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "from ray.rllib.algorithms.simple_q import SimpleQConfig\n",
    "from ray.rllib.algorithms.dqn.dqn_torch_policy import DQNTorchModel\n",
    "from ray.rllib.algorithms.simple_q.simple_q_torch_policy import SimpleQTorchPolicy\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "import deflector_gym\n",
    "from operator import itemgetter\n",
    "\n",
    "def init_params(net, val=np.sqrt(2)):\n",
    "    for module in net.modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            nn.init.orthogonal_(module.weight, val)\n",
    "            module.bias.data.zero_()\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.orthogonal_(module.weight, val)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "class convrelu(nn.Module):\n",
    "    def __init__(self, nin, nout):\n",
    "        super().__init__()\n",
    "        self.convrelu = nn.Sequential(\n",
    "            nn.Conv1d(nin, nout, 3, padding='same', padding_mode='circular'),\n",
    "            nn.BatchNorm1d(nout),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convrelu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ShallowUQnet(TorchModelV2, nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            obs_space,\n",
    "            action_space,\n",
    "            num_outputs,\n",
    "            model_config,\n",
    "            name,\n",
    "            **kwargs,\n",
    "        ):\n",
    "        TorchModelV2.__init__(\n",
    "            self,\n",
    "            obs_space,\n",
    "            action_space,\n",
    "            num_outputs,\n",
    "            model_config,\n",
    "            name,\n",
    "            **kwargs,\n",
    "        )\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        self.effdata = []\n",
    "        self.score_sum = []\n",
    "        self.score_init_final = []\n",
    "        self.ncells = 256\n",
    "        init_params(self)\n",
    "\n",
    "\n",
    "        self.conv1_1 = nn.Conv1d(1, 16, 3, padding='same', bias=True, padding_mode='circular')\n",
    "        self.conv1_2 = convrelu(16, 16)\n",
    "        self.conv1_3 = convrelu(16, 16)\n",
    "        self.pool_1 = nn.MaxPool1d(2)  # non-Uniform\n",
    "\n",
    "        self.conv2_1 = nn.Conv1d(16, 32, 3, padding='same', bias=True, padding_mode='circular')\n",
    "        self.conv2_2 = convrelu(32, 32)\n",
    "        self.conv2_3 = convrelu(32, 32)\n",
    "        self.pool_2 = nn.MaxPool1d(2)  # non-Uniform\n",
    "\n",
    "        self.conv3_1 = nn.Conv1d(32, 32, 3, padding='same', bias=True, padding_mode='circular')\n",
    "        self.conv3_2 = convrelu(32, 32)\n",
    "        self.conv3_3 = convrelu(32, 32)\n",
    "        self.pool_3 = nn.MaxPool1d(2)  # Uniform (X\n",
    "\n",
    "        self.conv4_1 = nn.Conv1d(32, 32, 3, padding='same', bias=True, padding_mode='circular')\n",
    "        self.conv4_2 = convrelu(32, 32)\n",
    "        self.conv4_3 = convrelu(32, 32)\n",
    "        self.pool_4 = nn.MaxPool1d(2)  # Uniform (X\n",
    "\n",
    "        self.conv6_1 = nn.Conv1d(32, 32, 3, padding='same', bias=True, padding_mode='circular')\n",
    "        self.conv6_2 = convrelu(32, 32)\n",
    "        self.conv6_3 = convrelu(32, 32)\n",
    "        self.upsam_6 = nn.Upsample(scale_factor=2)  # Uniform (X\n",
    "\n",
    "        self.conv8_1 = nn.Conv1d(32 + 32, 32, 3, padding='same', bias=True, padding_mode='circular')\n",
    "        self.conv8_2 = convrelu(32, 32)\n",
    "        self.conv8_3 = convrelu(32, 32)\n",
    "        self.upsam_8 = nn.Upsample(scale_factor=2)  # Uniform (X\n",
    "\n",
    "        self.conv9_1 = nn.Conv1d(32 + 32, 32, 3, padding='same', bias=True, padding_mode='circular')\n",
    "        self.conv9_2 = convrelu(32, 32)\n",
    "        self.conv9_3 = convrelu(32, 32)\n",
    "        self.upsam_9 = nn.Upsample(scale_factor=2)  # Uniform (X\n",
    "\n",
    "        self.conv10_1 = nn.Conv1d(32 + 32, 32, 3, padding='same', bias=True, padding_mode='circular')\n",
    "        self.conv10_2 = convrelu(32, 32)\n",
    "        self.conv10_3 = convrelu(32, 32)\n",
    "        self.upsam_10 = nn.Upsample(scale_factor=2)  # non-Uniform\n",
    "\n",
    "        self.conv11_1 = nn.Conv1d(16 + 32, 16, 3, padding='same', bias=True, padding_mode='circular')\n",
    "        self.conv11_2 = convrelu(16, 16)\n",
    "        self.conv11_3 = convrelu(16, 16)\n",
    "\n",
    "        self.conv11_fin = nn.Conv1d(16, 1, 3, padding='same', bias=True, padding_mode='circular')\n",
    "        # self.lin = nn.LazyLinear(256)\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        img = input_dict['obs']\n",
    "\n",
    "        res1_1 = self.conv1_1(img)\n",
    "        temp = self.conv1_2(res1_1)\n",
    "        temp = self.conv1_3(temp) + res1_1\n",
    "        shortcut1 = temp\n",
    "        temp = self.pool_1(shortcut1)\n",
    "\n",
    "        res2_1 = self.conv2_1(temp)\n",
    "        temp = self.conv2_2(res2_1)\n",
    "        temp = self.conv2_3(temp) + res2_1\n",
    "        shortcut2 = temp\n",
    "        temp = self.pool_2(shortcut2)\n",
    "\n",
    "        res3_1 = self.conv3_1(temp)\n",
    "        temp = self.conv3_2(res3_1)\n",
    "        temp = self.conv3_3(temp) + res3_1\n",
    "        shortcut3 = temp\n",
    "        temp = self.pool_3(shortcut3)\n",
    "\n",
    "        res4_1 = self.conv4_1(temp)\n",
    "        temp = self.conv4_2(res4_1)\n",
    "        temp = self.conv4_3(temp) + res4_1\n",
    "        shortcut4 = temp\n",
    "        temp = self.pool_4(shortcut4)\n",
    "\n",
    "        res6_1 = self.conv6_1(temp)\n",
    "        temp = self.conv6_2(res6_1)\n",
    "        temp = self.conv6_3(temp) + res6_1\n",
    "        temp = self.upsam_6(temp)\n",
    "        temp = torch.cat([temp, shortcut4], dim=1)  ######\n",
    "\n",
    "        res8_1 = self.conv8_1(temp)\n",
    "        temp = self.conv8_2(res8_1)\n",
    "        temp = self.conv8_3(temp) + res8_1\n",
    "        temp = self.upsam_8(temp)\n",
    "        temp = torch.cat([temp, shortcut3], dim=1)  ######\n",
    "\n",
    "        res9_1 = self.conv9_1(temp)\n",
    "        temp = self.conv9_2(res9_1)\n",
    "        temp = self.conv9_3(temp) + res9_1\n",
    "        temp = self.upsam_9(temp)\n",
    "        temp = torch.cat([temp, shortcut2], dim=1)  ######\n",
    "\n",
    "        res10_1 = self.conv10_1(temp)\n",
    "        temp = self.conv10_2(res10_1)\n",
    "        temp = self.conv10_3(temp) + res10_1\n",
    "        temp = self.upsam_10(temp)\n",
    "        temp = torch.cat([temp, shortcut1], dim=1)  ######\n",
    "\n",
    "        res11_1 = self.conv11_1(temp)\n",
    "        temp = self.conv11_2(res11_1)\n",
    "        temp = self.conv11_3(temp) + res11_1\n",
    "        temp = self.conv11_fin(temp)\n",
    "\n",
    "        # out = self.lin(temp)\n",
    "        \n",
    "        temp = temp.flatten(1)\n",
    "        \n",
    "        # self._value_logits = temp.argmax()\n",
    "        # print(self._value_logits.shape)\n",
    "\n",
    "        return temp, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.spaces.MultiDiscrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHot(gym.ObservationWrapper):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0., high=1.,\n",
    "            shape=(n_cells,), #### TODO fix shape\n",
    "            dtype=np.float64\n",
    "        )\n",
    "        \n",
    "    def observation(self, obs):\n",
    "        obs[obs == -1] = 0\n",
    "\n",
    "        return obs\n",
    "    # def __init__(self, env) -> None:\n",
    "    #     super().__init__(env)\n",
    "    #     self.observation_space = gym.spaces.MultiDiscrete(\n",
    "    #         low=-1., high=1.,\n",
    "    #         shape=(n_cells,), #### TODO fix shape\n",
    "    #         dtype=np.float64\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Callbacks(DefaultCallbacks):\n",
    "    def on_episode_end(\n",
    "            self,\n",
    "            *,\n",
    "            worker,\n",
    "            base_env,\n",
    "            policies,\n",
    "            episode,\n",
    "            **kwargs,\n",
    "    ) -> None:\n",
    "        envs = base_env.get_sub_environments()\n",
    "        bests = [e.best for e in envs]\n",
    "        best = max(bests, key=itemgetter(0))\n",
    "        max_eff = best[0]\n",
    "        # img = best[1][np.newaxis, np.newaxis, :].repeat(32, axis=1)\n",
    "        # mean_eff = np.array([i[0] for i in bests]).mean()\n",
    "\n",
    "        episode.custom_metrics['best_efficiency'] = max_eff\n",
    "        # episode.custom_metrics['mean_efficiency'] = mean_eff\n",
    "\n",
    "        # episode.media['best_structure'] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-11-17 21:13:37</td></tr>\n",
       "<tr><td>Running for: </td><td>03:21:17.75        </td></tr>\n",
       "<tr><td>Memory:      </td><td>62.4/251.5 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/72 CPUs, 0/4 GPUs, 0.0/153.99 GiB heap, 0.0/69.99 GiB objects (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                    </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  num_recreated_worker\n",
       "s</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_MeentIndex-v0_24e60_00000</td><td>TERMINATED</td><td>143.248.153.115:2808284</td><td style=\"text-align: right;\">   200</td><td style=\"text-align: right;\">         12049.9</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">0.0339682</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">            0.171579</td><td style=\"text-align: right;\">          -0.0333579</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=2808284)\u001b[0m 2022-11-17 17:52:22,447\tINFO simple_q.py:307 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=2808284)\u001b[0m 2022-11-17 17:52:22,449\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=2808284)\u001b[0m 2022-11-17 17:52:27,161\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                                                                                              </th><th>custom_metrics                                                                                                                        </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname                   </th><th>info  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip        </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_recreated_workers</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                                                                                                                                                                                                                                                                                                                                                                       </th><th style=\"text-align: right;\">    pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                    </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                                           </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_MeentIndex-v0_24e60_00000</td><td style=\"text-align: right;\">                 200000</td><td>{&#x27;num_env_steps_sampled&#x27;: 200000, &#x27;num_env_steps_trained&#x27;: 1592000, &#x27;num_agent_steps_sampled&#x27;: 200000, &#x27;num_agent_steps_trained&#x27;: 1592000, &#x27;last_target_update_ts&#x27;: 199504, &#x27;num_target_updates&#x27;: 398}</td><td>{&#x27;best_efficiency_mean&#x27;: 0.15977086460438988, &#x27;best_efficiency_min&#x27;: 0.053865344287038174, &#x27;best_efficiency_max&#x27;: 0.34347248518865314}</td><td>2022-11-17_21-13-37</td><td>True  </td><td style=\"text-align: right;\">              1024</td><td>{}             </td><td style=\"text-align: right;\">            0.171579</td><td style=\"text-align: right;\">            0.0339682</td><td style=\"text-align: right;\">          -0.0333579</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">             195</td><td>9422b69edde14b65bba1eb68cf17018f</td><td>rayleigh-B7105F48TV4HR-2T-G</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;custom_metrics&#x27;: {}, &#x27;learner_stats&#x27;: {&#x27;mean_q&#x27;: 15220645888.0, &#x27;min_q&#x27;: 601132160.0, &#x27;max_q&#x27;: 43182227456.0, &#x27;cur_lr&#x27;: 0.0005}, &#x27;model&#x27;: {}, &#x27;td_error&#x27;: array([-6.8721050e+08, -2.4957920e+08, -6.8721050e+08, -1.5144269e+08,\n",
       "       -4.2622182e+08,  2.3760384e+08, -3.9450112e+08, -5.5739187e+08,\n",
       "        1.9858637e+08, -8.3678413e+08, -7.0995251e+08, -1.3656602e+08,\n",
       "       -4.2924339e+08,  3.8496768e+07,  8.4837581e+08,  1.4258637e+08,\n",
       "        2.3984640e+07,  6.4837120e+07, -4.5959014e+08,  3.9655731e+08,\n",
       "       -4.5422019e+09, -2.4957920e+08,  7.5013427e+08, -5.8420224e+08,\n",
       "       -6.7792896e+08, -1.1958682e+08,  1.6794726e+08,  1.8855117e+08,\n",
       "       -9.8466816e+08,  4.1121587e+08,  5.6833434e+08,  1.6306790e+09],\n",
       "      dtype=float32), &#x27;mean_td_error&#x27;: -225499088.0}}, &#x27;num_env_steps_sampled&#x27;: 200000, &#x27;num_env_steps_trained&#x27;: 1592000, &#x27;num_agent_steps_sampled&#x27;: 200000, &#x27;num_agent_steps_trained&#x27;: 1592000, &#x27;last_target_update_ts&#x27;: 199504, &#x27;num_target_updates&#x27;: 398}       </td><td style=\"text-align: right;\">                       200</td><td>143.248.153.115</td><td style=\"text-align: right;\">                   200000</td><td style=\"text-align: right;\">                  1592000</td><td style=\"text-align: right;\">                 200000</td><td style=\"text-align: right;\">                             1000</td><td style=\"text-align: right;\">                1592000</td><td style=\"text-align: right;\">                             8000</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         8000</td><td>{&#x27;cpu_util_percent&#x27;: 60.02934782608696, &#x27;ram_util_percent&#x27;: 24.693478260869572, &#x27;gpu_util_percent0&#x27;: 0.1848913043478261, &#x27;vram_util_percent0&#x27;: 0.7355468749999998, &#x27;gpu_util_percent1&#x27;: 0.031521739130434774, &#x27;vram_util_percent1&#x27;: 0.17841796875000004, &#x27;gpu_util_percent2&#x27;: 0.00010869565217391305, &#x27;vram_util_percent2&#x27;: 0.00048828125, &#x27;gpu_util_percent3&#x27;: 0.0002173913043478261, &#x27;vram_util_percent3&#x27;: 0.00048828125}</td><td style=\"text-align: right;\">2808284</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 0.47938471272842087, &#x27;mean_inference_ms&#x27;: 9.066336269441424, &#x27;mean_action_processing_ms&#x27;: 0.07009383916206997, &#x27;mean_env_wait_ms&#x27;: 20.188486318527275, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 0.17157877919177966, &#x27;episode_reward_min&#x27;: -0.03335788297334374, &#x27;episode_reward_mean&#x27;: 0.033968192783428316, &#x27;episode_len_mean&#x27;: 1024.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 1, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {&#x27;best_efficiency_mean&#x27;: 0.15977086460438988, &#x27;best_efficiency_min&#x27;: 0.053865344287038174, &#x27;best_efficiency_max&#x27;: 0.34347248518865314}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [0.009409476661925396, -0.016949291277859296, 0.08036058838381828, 0.0300383704817059, 0.04590879882878562, 0.0569851250964622, 0.01797723453908672, 0.019369686693044966, 0.00642935801993726, 0.07039444943227376, 0.03461076185254807, 0.1077086484081064, 0.022732348504180308, 0.00926802498951599, 0.13266162228969744, -0.03335788297334374, 0.00231473719494326, 0.020058340609632228, 0.01917600119725949, 0.07614703933064804, 0.046638797802705134, -0.002933174534071454, 0.058398265357221174, 0.08404340908652266, 0.008218986580348496, 0.08388369428842916, 0.02643597093361139, -0.00038658347731100346, 0.05136851699444345, 0.17157877919177966, 0.014656120388461202, 0.08836484013967466, 0.047250257676878786, -0.0057960965771535556, 0.007429246653615404, 0.011317919969374875, 0.012162249979924628, 0.02373330900437821, -0.0029389714047068365, 0.05330020542370838, 0.005640154034666344, 0.11593519695766893, 0.08013000637496437, 0.06637419057684901, -0.02383774303459022, 0.03348495180522261, -0.031463688770816886, 0.06576570403263468, 3.539973088098874e-05, 0.035370028677920384, 0.0718978078408373, 0.011860244711461833, -0.0002663473898134594, 0.011881383649662488, -0.02306618835065075, 0.008629080356941807, 0.004247198170419467, -0.008124477940328115, -0.002426806822832162, 0.0068751464260916086, 0.03564666964824132, 0.03553417598985162, 0.013196688740918089, 0.06696193281610457, 0.06214510734879784, 0.09879451516090258, 0.05773088914461408, 0.015571799032926235, 0.009097372644176491, 0.030231074089595224, 0.029404461964539608, 0.002227846384746244, 0.06430179258311632, 0.1053225713666956, 0.08351545416422784, -0.017436548227893464, 0.013759711443219982, -0.009610052184127478, 3.4699527112302606e-05, 0.039728355696849765, 0.02297069803821069, -0.00604548169096656, 0.002272149769291777, 0.005391850002465006, 0.023546720470885598, 0.014806147863874106, -0.025802469456619688, 0.028228762569675638, 0.006749439155327547, 0.07963682971806689, 0.011986558481403045, 0.10200344412880502, 0.02227611580669326, 0.1112980481014064, 0.05637665946701863, 0.06195065279079312, 0.00897557591562596, 0.0127651947261011, 0.08626993274891717, 0.11809350962384943], &#x27;episode_lengths&#x27;: [1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.47938471272842087, &#x27;mean_inference_ms&#x27;: 9.066336269441424, &#x27;mean_action_processing_ms&#x27;: 0.07009383916206997, &#x27;mean_env_wait_ms&#x27;: 20.188486318527275, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             12049.9</td><td style=\"text-align: right;\">           92.8394</td><td style=\"text-align: right;\">       12049.9</td><td>{&#x27;training_iteration_time_ms&#x27;: 300.591, &#x27;load_time_ms&#x27;: 1.896, &#x27;load_throughput&#x27;: 16874.879, &#x27;learn_time_ms&#x27;: 114.384, &#x27;learn_throughput&#x27;: 279.76, &#x27;synch_weights_time_ms&#x27;: 0.07}</td><td style=\"text-align: right;\"> 1668687217</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">           200000</td><td style=\"text-align: right;\">                 200</td><td>24e60_00000</td><td style=\"text-align: right;\">       4.5695</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=2808284)\u001b[0m 2022-11-17 17:52:51,956\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
      "2022-11-17 21:13:38,377\tINFO tune.py:777 -- Total run time: 12078.81 seconds (12077.68 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "stop = {\n",
    "    # \"training_iteration\": args.stop_iters,\n",
    "    \"timesteps_total\": 200000,\n",
    "    # \"episode_reward_mean\": args.stop_reward,\n",
    "}\n",
    "def make_env(config):\n",
    "    e = deflector_gym.make('MeentIndex-v0')\n",
    "    e = BestRecorder(e)\n",
    "    e = OneHot(e)\n",
    "    e = ExpandObservation(e)\n",
    "    e = NormalizeReward(e)\n",
    "    return e\n",
    "\n",
    "register_env('MeentIndex-v0', make_env)\n",
    "ModelCatalog.register_custom_model(ShallowUQnet.__name__, ShallowUQnet)\n",
    "config = DQNConfig()\n",
    "config = config.rollouts(horizon=1024)\\\n",
    "    .framework(framework='torch')\\\n",
    "        .environment(env='MeentIndex-v0')\\\n",
    "            .resources(num_gpus=1)\\\n",
    "                .training(model={'custom_model': ShallowUQnet.__name__})\\\n",
    "                    .callbacks(Callbacks)\n",
    "                    \n",
    "tuner = tune.Tuner(\n",
    "    'DQN',\n",
    "    param_space=config.to_dict(),\n",
    "    # tune_config=tune.TuneConfig(),\n",
    "    run_config=air.RunConfig(\n",
    "        stop=stop,\n",
    "        # callbacks=Callbacks,\n",
    "        local_dir='/mnt/8tb/anthony/pirl',\n",
    "        name='debug-onehot'\n",
    "    ),\n",
    ")\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(metrics={'custom_metrics': {'best_efficiency_mean': 0.15977086460438988, 'best_efficiency_min': 0.053865344287038174, 'best_efficiency_max': 0.34347248518865314}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'mean_q': 15220645888.0, 'min_q': 601132160.0, 'max_q': 43182227456.0, 'cur_lr': 0.0005}, 'model': {}, 'td_error': array([-6.8721050e+08, -2.4957920e+08, -6.8721050e+08, -1.5144269e+08,\n",
       "       -4.2622182e+08,  2.3760384e+08, -3.9450112e+08, -5.5739187e+08,\n",
       "        1.9858637e+08, -8.3678413e+08, -7.0995251e+08, -1.3656602e+08,\n",
       "       -4.2924339e+08,  3.8496768e+07,  8.4837581e+08,  1.4258637e+08,\n",
       "        2.3984640e+07,  6.4837120e+07, -4.5959014e+08,  3.9655731e+08,\n",
       "       -4.5422019e+09, -2.4957920e+08,  7.5013427e+08, -5.8420224e+08,\n",
       "       -6.7792896e+08, -1.1958682e+08,  1.6794726e+08,  1.8855117e+08,\n",
       "       -9.8466816e+08,  4.1121587e+08,  5.6833434e+08,  1.6306790e+09],\n",
       "      dtype=float32), 'mean_td_error': -225499088.0}}, 'num_env_steps_sampled': 200000, 'num_env_steps_trained': 1592000, 'num_agent_steps_sampled': 200000, 'num_agent_steps_trained': 1592000, 'last_target_update_ts': 199504, 'num_target_updates': 398}, 'sampler_results': {'episode_reward_max': 0.17157877919177966, 'episode_reward_min': -0.03335788297334374, 'episode_reward_mean': 0.033968192783428316, 'episode_len_mean': 1024.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'best_efficiency_mean': 0.15977086460438988, 'best_efficiency_min': 0.053865344287038174, 'best_efficiency_max': 0.34347248518865314}, 'hist_stats': {'episode_reward': [0.009409476661925396, -0.016949291277859296, 0.08036058838381828, 0.0300383704817059, 0.04590879882878562, 0.0569851250964622, 0.01797723453908672, 0.019369686693044966, 0.00642935801993726, 0.07039444943227376, 0.03461076185254807, 0.1077086484081064, 0.022732348504180308, 0.00926802498951599, 0.13266162228969744, -0.03335788297334374, 0.00231473719494326, 0.020058340609632228, 0.01917600119725949, 0.07614703933064804, 0.046638797802705134, -0.002933174534071454, 0.058398265357221174, 0.08404340908652266, 0.008218986580348496, 0.08388369428842916, 0.02643597093361139, -0.00038658347731100346, 0.05136851699444345, 0.17157877919177966, 0.014656120388461202, 0.08836484013967466, 0.047250257676878786, -0.0057960965771535556, 0.007429246653615404, 0.011317919969374875, 0.012162249979924628, 0.02373330900437821, -0.0029389714047068365, 0.05330020542370838, 0.005640154034666344, 0.11593519695766893, 0.08013000637496437, 0.06637419057684901, -0.02383774303459022, 0.03348495180522261, -0.031463688770816886, 0.06576570403263468, 3.539973088098874e-05, 0.035370028677920384, 0.0718978078408373, 0.011860244711461833, -0.0002663473898134594, 0.011881383649662488, -0.02306618835065075, 0.008629080356941807, 0.004247198170419467, -0.008124477940328115, -0.002426806822832162, 0.0068751464260916086, 0.03564666964824132, 0.03553417598985162, 0.013196688740918089, 0.06696193281610457, 0.06214510734879784, 0.09879451516090258, 0.05773088914461408, 0.015571799032926235, 0.009097372644176491, 0.030231074089595224, 0.029404461964539608, 0.002227846384746244, 0.06430179258311632, 0.1053225713666956, 0.08351545416422784, -0.017436548227893464, 0.013759711443219982, -0.009610052184127478, 3.4699527112302606e-05, 0.039728355696849765, 0.02297069803821069, -0.00604548169096656, 0.002272149769291777, 0.005391850002465006, 0.023546720470885598, 0.014806147863874106, -0.025802469456619688, 0.028228762569675638, 0.006749439155327547, 0.07963682971806689, 0.011986558481403045, 0.10200344412880502, 0.02227611580669326, 0.1112980481014064, 0.05637665946701863, 0.06195065279079312, 0.00897557591562596, 0.0127651947261011, 0.08626993274891717, 0.11809350962384943], 'episode_lengths': [1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.47938471272842087, 'mean_inference_ms': 9.066336269441424, 'mean_action_processing_ms': 0.07009383916206997, 'mean_env_wait_ms': 20.188486318527275, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 0.17157877919177966, 'episode_reward_min': -0.03335788297334374, 'episode_reward_mean': 0.033968192783428316, 'episode_len_mean': 1024.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.009409476661925396, -0.016949291277859296, 0.08036058838381828, 0.0300383704817059, 0.04590879882878562, 0.0569851250964622, 0.01797723453908672, 0.019369686693044966, 0.00642935801993726, 0.07039444943227376, 0.03461076185254807, 0.1077086484081064, 0.022732348504180308, 0.00926802498951599, 0.13266162228969744, -0.03335788297334374, 0.00231473719494326, 0.020058340609632228, 0.01917600119725949, 0.07614703933064804, 0.046638797802705134, -0.002933174534071454, 0.058398265357221174, 0.08404340908652266, 0.008218986580348496, 0.08388369428842916, 0.02643597093361139, -0.00038658347731100346, 0.05136851699444345, 0.17157877919177966, 0.014656120388461202, 0.08836484013967466, 0.047250257676878786, -0.0057960965771535556, 0.007429246653615404, 0.011317919969374875, 0.012162249979924628, 0.02373330900437821, -0.0029389714047068365, 0.05330020542370838, 0.005640154034666344, 0.11593519695766893, 0.08013000637496437, 0.06637419057684901, -0.02383774303459022, 0.03348495180522261, -0.031463688770816886, 0.06576570403263468, 3.539973088098874e-05, 0.035370028677920384, 0.0718978078408373, 0.011860244711461833, -0.0002663473898134594, 0.011881383649662488, -0.02306618835065075, 0.008629080356941807, 0.004247198170419467, -0.008124477940328115, -0.002426806822832162, 0.0068751464260916086, 0.03564666964824132, 0.03553417598985162, 0.013196688740918089, 0.06696193281610457, 0.06214510734879784, 0.09879451516090258, 0.05773088914461408, 0.015571799032926235, 0.009097372644176491, 0.030231074089595224, 0.029404461964539608, 0.002227846384746244, 0.06430179258311632, 0.1053225713666956, 0.08351545416422784, -0.017436548227893464, 0.013759711443219982, -0.009610052184127478, 3.4699527112302606e-05, 0.039728355696849765, 0.02297069803821069, -0.00604548169096656, 0.002272149769291777, 0.005391850002465006, 0.023546720470885598, 0.014806147863874106, -0.025802469456619688, 0.028228762569675638, 0.006749439155327547, 0.07963682971806689, 0.011986558481403045, 0.10200344412880502, 0.02227611580669326, 0.1112980481014064, 0.05637665946701863, 0.06195065279079312, 0.00897557591562596, 0.0127651947261011, 0.08626993274891717, 0.11809350962384943], 'episode_lengths': [1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.47938471272842087, 'mean_inference_ms': 9.066336269441424, 'mean_action_processing_ms': 0.07009383916206997, 'mean_env_wait_ms': 20.188486318527275, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 0, 'num_agent_steps_sampled': 200000, 'num_agent_steps_trained': 1592000, 'num_env_steps_sampled': 200000, 'num_env_steps_trained': 1592000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 8000, 'num_steps_trained_this_iter': 8000, 'agent_timesteps_total': 200000, 'timers': {'training_iteration_time_ms': 300.591, 'load_time_ms': 1.896, 'load_throughput': 16874.879, 'learn_time_ms': 114.384, 'learn_throughput': 279.76, 'synch_weights_time_ms': 0.07}, 'counters': {'num_env_steps_sampled': 200000, 'num_env_steps_trained': 1592000, 'num_agent_steps_sampled': 200000, 'num_agent_steps_trained': 1592000, 'last_target_update_ts': 199504, 'num_target_updates': 398}, 'done': True, 'trial_id': '24e60_00000', 'perf': {'cpu_util_percent': 60.02934782608696, 'ram_util_percent': 24.693478260869572, 'gpu_util_percent0': 0.1848913043478261, 'vram_util_percent0': 0.7355468749999998, 'gpu_util_percent1': 0.031521739130434774, 'vram_util_percent1': 0.17841796875000004, 'gpu_util_percent2': 0.00010869565217391305, 'vram_util_percent2': 0.00048828125, 'gpu_util_percent3': 0.0002173913043478261, 'vram_util_percent3': 0.00048828125}, 'experiment_tag': '0'}, error=None, log_dir=PosixPath('/mnt/8tb/anthony/pirl/debug1/DQN_MeentIndex-v0_24e60_00000_0_2022-11-17_17-52-19'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_best_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4921b80730ef6bb183c476179c2aff33b6213081762e775ca242bf322e0592a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
